/**
 * DO NOT EDIT THIS FILE!
 * File automatically generated by
 *   /shared/gem5/src/mem/slicc/symbols/StateMachine.py:1348
 */

// Created by slicc definition of Module "AMD Hammer-like protocol"

#include <sys/types.h>
#include <unistd.h>

#include <cassert>
#include <sstream>
#include <string>
#include <typeinfo>

#include "mem/ruby/common/BoolVec.hh"

#include "base/compiler.hh"
#include "base/cprintf.hh"

#include "debug/RubyGenerated.hh"
#include "debug/RubySlicc.hh"
#include "mem/ruby/network/Network.hh"
#include "mem/ruby/protocol/L1Cache_Controller.hh"
#include "mem/ruby/protocol/L1Cache_Event.hh"
#include "mem/ruby/protocol/L1Cache_State.hh"
#include "mem/ruby/protocol/Types.hh"
#include "mem/ruby/system/RubySystem.hh"

#include "mem/ruby/slicc_interface/RubySlicc_includes.hh"
#include "mem/ruby/protocol/TBETable.hh"
namespace gem5
{

namespace ruby
{

int L1Cache_Controller::m_num_controllers = 0;
std::vector<statistics::Vector *>  L1Cache_Controller::eventVec;
std::vector<std::vector<statistics::Vector *> >  L1Cache_Controller::transVec;

// for adding information to the protocol debug trace
std::stringstream L1Cache_transitionComment;

#ifndef NDEBUG
#define APPEND_TRANSITION_COMMENT(str) (L1Cache_transitionComment << str)
#else
#define APPEND_TRANSITION_COMMENT(str) do {} while (0)
#endif

/** \brief constructor */
L1Cache_Controller::L1Cache_Controller(const Params &p)
    : AbstractController(p)
{
    m_machineID.type = MachineType_L1Cache;
    m_machineID.num = m_version;
    m_num_controllers++;
    p.ruby_system->registerAbstractController(this);

    m_in_ports = 4;
    m_sequencer_ptr = p.sequencer;
    if (m_sequencer_ptr != NULL) {
        m_sequencer_ptr->setController(this);
    }
    m_L1Icache_ptr = p.L1Icache;
    m_L1Dcache_ptr = p.L1Dcache;
    m_L2cache_ptr = p.L2cache;
    m_cache_response_latency = p.cache_response_latency;
    m_issue_latency = p.issue_latency;
    m_l2_cache_hit_latency = p.l2_cache_hit_latency;
    m_no_mig_atomic = p.no_mig_atomic;
    m_send_evictions = p.send_evictions;
    m_requestFromCache_ptr = p.requestFromCache;
    m_responseFromCache_ptr = p.responseFromCache;
    m_unblockFromCache_ptr = p.unblockFromCache;
    m_forwardToCache_ptr = p.forwardToCache;
    m_responseToCache_ptr = p.responseToCache;
    m_mandatoryQueue_ptr = p.mandatoryQueue;
    m_triggerQueue_ptr = p.triggerQueue;

    for (int state = 0; state < L1Cache_State_NUM; state++) {
        for (int event = 0; event < L1Cache_Event_NUM; event++) {
            m_possible[state][event] = false;
            m_counters[state][event] = 0;
        }
    }
    for (int event = 0; event < L1Cache_Event_NUM; event++) {
        m_event_counters[event] = 0;
    }
}

void
L1Cache_Controller::initNetQueues()
{
    MachineType machine_type = string_to_MachineType("L1Cache");
    [[maybe_unused]] int base = MachineType_base_number(machine_type);

    assert(m_requestFromCache_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_requestFromCache_ptr->getOrdered(), 2,
                                     "request", m_requestFromCache_ptr);
    assert(m_responseFromCache_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_responseFromCache_ptr->getOrdered(), 4,
                                     "response", m_responseFromCache_ptr);
    assert(m_unblockFromCache_ptr != NULL);
    m_net_ptr->setToNetQueue(m_version + base, m_unblockFromCache_ptr->getOrdered(), 5,
                                     "unblock", m_unblockFromCache_ptr);
    assert(m_forwardToCache_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_forwardToCache_ptr->getOrdered(), 3,
                                     "forward", m_forwardToCache_ptr);
    assert(m_responseToCache_ptr != NULL);
    m_net_ptr->setFromNetQueue(m_version + base, m_responseToCache_ptr->getOrdered(), 4,
                                     "response", m_responseToCache_ptr);
}

void
L1Cache_Controller::init()
{
    // initialize objects
    m_TBEs_ptr  = new TBETable<L1Cache_TBE>(m_number_of_TBEs);
    assert(m_TBEs_ptr != NULL);


    (*m_triggerQueue_ptr).setConsumer(this);
    (*m_responseToCache_ptr).setConsumer(this);
    (*m_forwardToCache_ptr).setConsumer(this);
    (*m_mandatoryQueue_ptr).setConsumer(this);

    possibleTransition(L1Cache_State_IM, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_II, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_II, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_IR, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_SR, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_OR, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MR, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MMR, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_S, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_O, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_M, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_L1_to_L2);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Trigger_L2_to_L1D);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Trigger_L2_to_L1D);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Trigger_L2_to_L1D);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Trigger_L2_to_L1D);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Trigger_L2_to_L1I);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Trigger_L2_to_L1I);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Trigger_L2_to_L1I);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Trigger_L2_to_L1I);
    possibleTransition(L1Cache_State_ST, L1Cache_Event_Complete_L2_to_L1);
    possibleTransition(L1Cache_State_OT, L1Cache_Event_Complete_L2_to_L1);
    possibleTransition(L1Cache_State_MT, L1Cache_Event_Complete_L2_to_L1);
    possibleTransition(L1Cache_State_MMT, L1Cache_Event_Complete_L2_to_L1);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_IR, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_IR, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_IR, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_IR, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_I, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_I, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_SR, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_SR, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_SR, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_SR, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_S, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_S, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_S, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_OR, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_OR, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_OR, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_OR, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_O, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_O, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_O, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MMR, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MMR, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MMR, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MMR, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MR, L1Cache_Event_Flush_line);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Block_Ack);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_MM, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MR, L1Cache_Event_Load);
    possibleTransition(L1Cache_State_MR, L1Cache_Event_Ifetch);
    possibleTransition(L1Cache_State_MR, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_M, L1Cache_Event_L2_Replacement);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_M, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_M, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Data);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Data);
    possibleTransition(L1Cache_State_IM, L1Cache_Event_Exclusive_Data);
    possibleTransition(L1Cache_State_IM_F, L1Cache_Event_Exclusive_Data);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Data);
    possibleTransition(L1Cache_State_SM, L1Cache_Event_Exclusive_Data);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Data);
    possibleTransition(L1Cache_State_SM_F, L1Cache_Event_Exclusive_Data);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_ISM, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_ISM_F, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_All_acks);
    possibleTransition(L1Cache_State_OM, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_All_acks);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_All_acks);
    possibleTransition(L1Cache_State_OM_F, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Shared_Ack);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Data);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Exclusive_Data);
    possibleTransition(L1Cache_State_IS, L1Cache_Event_Shared_Data);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_Shared_Ack);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_All_acks);
    possibleTransition(L1Cache_State_SS, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_MM_W, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_MM_WF, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_Store);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_Ack);
    possibleTransition(L1Cache_State_M_W, L1Cache_Event_All_acks_no_sharers);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Merged_GETS);
    possibleTransition(L1Cache_State_MI, L1Cache_Event_Writeback_Ack);
    possibleTransition(L1Cache_State_MI_F, L1Cache_Event_Writeback_Ack);
    possibleTransition(L1Cache_State_OI, L1Cache_Event_Writeback_Ack);
    possibleTransition(L1Cache_State_II, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Writeback_Ack);
    possibleTransition(L1Cache_State_II, L1Cache_Event_Writeback_Nack);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Other_GETX);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Invalidate);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Other_GETS);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_NC_DMA_GETS);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Other_GETS_No_Mig);
    possibleTransition(L1Cache_State_MM_F, L1Cache_Event_Merged_GETS);
    AbstractController::init();
    resetStats();
}
Sequencer*
L1Cache_Controller::getCPUSequencer() const
{
    if (NULL != m_sequencer_ptr && m_sequencer_ptr->isCPUSequencer()) {
        return m_sequencer_ptr;
    } else {
        return NULL;
    }
}

DMASequencer*
L1Cache_Controller::getDMASequencer() const
{
    return NULL;
}

GPUCoalescer*
L1Cache_Controller::getGPUCoalescer() const
{
    return NULL;
}

void
L1Cache_Controller::regStats()
{
    AbstractController::regStats();

    // For each type of controllers, one controller of that type is picked
    // to aggregate stats of all controllers of that type.
    if (m_version == 0) {

        Profiler *profiler = params().ruby_system->getProfiler();
        statistics::Group *profilerStatsPtr = &profiler->rubyProfilerStats;

        for (L1Cache_Event event = L1Cache_Event_FIRST;
             event < L1Cache_Event_NUM; ++event) {
            std::string stat_name =
                "L1Cache_Controller." + L1Cache_Event_to_string(event);
            statistics::Vector *t =
                new statistics::Vector(profilerStatsPtr, stat_name.c_str());
            t->init(m_num_controllers);
            t->flags(statistics::pdf | statistics::total |
                statistics::oneline | statistics::nozero);

            eventVec.push_back(t);
        }

        for (L1Cache_State state = L1Cache_State_FIRST;
             state < L1Cache_State_NUM; ++state) {

            transVec.push_back(std::vector<statistics::Vector *>());

            for (L1Cache_Event event = L1Cache_Event_FIRST;
                 event < L1Cache_Event_NUM; ++event) {
                std::string stat_name = "L1Cache_Controller." +
                    L1Cache_State_to_string(state) +
                    "." + L1Cache_Event_to_string(event);
                statistics::Vector *t = new statistics::Vector(
                    profilerStatsPtr, stat_name.c_str());
                t->init(m_num_controllers);
                t->flags(statistics::pdf | statistics::total |
                    statistics::oneline | statistics::nozero);
                transVec[state].push_back(t);
            }
        }
    }

    for (L1Cache_Event event = L1Cache_Event_FIRST;
                 event < L1Cache_Event_NUM; ++event) {
        std::string stat_name =
            "outTransLatHist." + L1Cache_Event_to_string(event);
        statistics::Histogram* t =
            new statistics::Histogram(&stats, stat_name.c_str());
        stats.outTransLatHist.push_back(t);
        t->init(5);
        t->flags(statistics::pdf | statistics::total |
                 statistics::oneline | statistics::nozero);

        statistics::Scalar* r = new statistics::Scalar(&stats,
                                             (stat_name + ".retries").c_str());
        stats.outTransLatHistRetries.push_back(r);
        r->flags(statistics::nozero);
    }

    for (L1Cache_Event event = L1Cache_Event_FIRST;
                 event < L1Cache_Event_NUM; ++event) {
        std::string stat_name = "inTransLatHist." +
                                L1Cache_Event_to_string(event);
        statistics::Scalar* r = new statistics::Scalar(&stats,
                                             (stat_name + ".total").c_str());
        stats.inTransLatTotal.push_back(r);
        r->flags(statistics::nozero);

        r = new statistics::Scalar(&stats,
                              (stat_name + ".retries").c_str());
        stats.inTransLatRetries.push_back(r);
        r->flags(statistics::nozero);

        stats.inTransLatHist.emplace_back();
        for (L1Cache_State initial_state = L1Cache_State_FIRST;
             initial_state < L1Cache_State_NUM; ++initial_state) {
            stats.inTransLatHist.back().emplace_back();
            for (L1Cache_State final_state = L1Cache_State_FIRST;
                 final_state < L1Cache_State_NUM; ++final_state) {
                std::string stat_name = "inTransLatHist." +
                    L1Cache_Event_to_string(event) + "." +
                    L1Cache_State_to_string(initial_state) + "." +
                    L1Cache_State_to_string(final_state);
                statistics::Histogram* t =
                    new statistics::Histogram(&stats, stat_name.c_str());
                stats.inTransLatHist.back().back().push_back(t);
                t->init(5);
                t->flags(statistics::pdf | statistics::total |
                         statistics::oneline | statistics::nozero);
            }
        }
    }
}

void
L1Cache_Controller::collateStats()
{
    for (L1Cache_Event event = L1Cache_Event_FIRST;
         event < L1Cache_Event_NUM; ++event) {
        for (unsigned int i = 0; i < m_num_controllers; ++i) {
            RubySystem *rs = params().ruby_system;
            std::map<uint32_t, AbstractController *>::iterator it =
                     rs->m_abstract_controls[MachineType_L1Cache].find(i);
            assert(it != rs->m_abstract_controls[MachineType_L1Cache].end());
            (*eventVec[event])[i] =
                ((L1Cache_Controller *)(*it).second)->getEventCount(event);
        }
    }

    for (L1Cache_State state = L1Cache_State_FIRST;
         state < L1Cache_State_NUM; ++state) {

        for (L1Cache_Event event = L1Cache_Event_FIRST;
             event < L1Cache_Event_NUM; ++event) {

            for (unsigned int i = 0; i < m_num_controllers; ++i) {
                RubySystem *rs = params().ruby_system;
                std::map<uint32_t, AbstractController *>::iterator it =
                         rs->m_abstract_controls[MachineType_L1Cache].find(i);
                assert(it != rs->m_abstract_controls[MachineType_L1Cache].end());
                (*transVec[state][event])[i] =
                    ((L1Cache_Controller *)(*it).second)->getTransitionCount(state, event);
            }
        }
    }
}

void
L1Cache_Controller::countTransition(L1Cache_State state, L1Cache_Event event)
{
    assert(m_possible[state][event]);
    m_counters[state][event]++;
    m_event_counters[event]++;
}
void
L1Cache_Controller::possibleTransition(L1Cache_State state,
                             L1Cache_Event event)
{
    m_possible[state][event] = true;
}

uint64_t
L1Cache_Controller::getEventCount(L1Cache_Event event)
{
    return m_event_counters[event];
}

bool
L1Cache_Controller::isPossible(L1Cache_State state, L1Cache_Event event)
{
    return m_possible[state][event];
}

uint64_t
L1Cache_Controller::getTransitionCount(L1Cache_State state,
                             L1Cache_Event event)
{
    return m_counters[state][event];
}

int
L1Cache_Controller::getNumControllers()
{
    return m_num_controllers;
}

MessageBuffer*
L1Cache_Controller::getMandatoryQueue() const
{
    return m_mandatoryQueue_ptr;
}

MessageBuffer*
L1Cache_Controller::getMemReqQueue() const
{
    return NULL;
}

MessageBuffer*
L1Cache_Controller::getMemRespQueue() const
{
    return NULL;
}

void
L1Cache_Controller::print(std::ostream& out) const
{
    out << "[L1Cache_Controller " << m_version << "]";
}

void L1Cache_Controller::resetStats()
{
    for (int state = 0; state < L1Cache_State_NUM; state++) {
        for (int event = 0; event < L1Cache_Event_NUM; event++) {
            m_counters[state][event] = 0;
        }
    }

    for (int event = 0; event < L1Cache_Event_NUM; event++) {
        m_event_counters[event] = 0;
    }

    AbstractController::resetStats();
}

// Set and Reset for cache_entry variable
void
L1Cache_Controller::set_cache_entry(L1Cache_Entry*& m_cache_entry_ptr, AbstractCacheEntry* m_new_cache_entry)
{
  m_cache_entry_ptr = (L1Cache_Entry*)m_new_cache_entry;
}

void
L1Cache_Controller::unset_cache_entry(L1Cache_Entry*& m_cache_entry_ptr)
{
  m_cache_entry_ptr = 0;
}

// Set and Reset for tbe variable
void
L1Cache_Controller::set_tbe(L1Cache_TBE*& m_tbe_ptr, L1Cache_TBE* m_new_tbe)
{
  m_tbe_ptr = m_new_tbe;
}

void
L1Cache_Controller::unset_tbe(L1Cache_TBE*& m_tbe_ptr)
{
  m_tbe_ptr = NULL;
}

void
L1Cache_Controller::recordCacheTrace(int cntrl, CacheRecorder* tr)
{
    m_L1Icache_ptr->recordCacheContents(cntrl, tr);
    m_L1Dcache_ptr->recordCacheContents(cntrl, tr);
    m_L2cache_ptr->recordCacheContents(cntrl, tr);
}

// Actions
/** \brief Issue GETS */
void
L1Cache_Controller::a_issueGETS(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing a_issueGETS\n");
    try {
       {
    std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:555: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceRequestType_GETS;
    (*out_msg).m_Requestor = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Request_Control;
    (*out_msg).m_InitialRequestTime = (curCycle());
    (*m_tbe_ptr).m_NumPendingMsgs = (machineCount(MachineType_L1Cache));
    ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:a_issueGETS: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Issue GETX */
void
L1Cache_Controller::b_issueGETX(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing b_issueGETX\n");
    try {
       {
    std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:570: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceRequestType_GETX;
    (*out_msg).m_Requestor = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Request_Control;
    (*out_msg).m_InitialRequestTime = (curCycle());
    (*m_tbe_ptr).m_NumPendingMsgs = (machineCount(MachineType_L1Cache));
    ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:b_issueGETX: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Issue GETX */
void
L1Cache_Controller::b_issueGETXIfMoreThanOne(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing b_issueGETXIfMoreThanOne\n");
    try {
           if (((machineCount(MachineType_L1Cache)) > (1))) {
        {
            std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
            #ifndef NDEBUG
            if (!((m_tbe_ptr != NULL))) {
                panic("Runtime Error at MOESI_hammer-cache.sm:586: %s.\n", "assert failure");

            }
            #endif
            ;
            (*out_msg).m_addr = addr;
            (*out_msg).m_Type = CoherenceRequestType_GETX;
            (*out_msg).m_Requestor = m_machineID;
            (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
            (*out_msg).m_MessageSize = MessageSizeType_Request_Control;
            (*out_msg).m_InitialRequestTime = (curCycle());
            ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
        }
    }
    (*m_tbe_ptr).m_NumPendingMsgs = (machineCount(MachineType_L1Cache));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:b_issueGETXIfMoreThanOne: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Issue GETF */
void
L1Cache_Controller::bf_issueGETF(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing bf_issueGETF\n");
    try {
       {
    std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:602: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceRequestType_GETF;
    (*out_msg).m_Requestor = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Request_Control;
    (*out_msg).m_InitialRequestTime = (curCycle());
    (*m_tbe_ptr).m_NumPendingMsgs = (machineCount(MachineType_L1Cache));
    ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:bf_issueGETF: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send exclusive data from cache to requestor */
void
L1Cache_Controller::c_sendExclusiveData(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing c_sendExclusiveData\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_cache_entry_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:618: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_EXCLUSIVE;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_DataBlk = (*m_cache_entry_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_cache_entry_ptr).m_Dirty;
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:c_sendExclusiveData: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send exclusive data from tbe to requestor */
void
L1Cache_Controller::ct_sendExclusiveDataFromTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ct_sendExclusiveDataFromTBE\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:641: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_EXCLUSIVE;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ct_sendExclusiveDataFromTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Issue PUT */
void
L1Cache_Controller::d_issuePUT(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing d_issuePUT\n");
    try {
       {
    std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceRequestType_PUT;
    (*out_msg).m_Requestor = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Writeback_Control;
    ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:d_issuePUT: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Issue PUTF */
void
L1Cache_Controller::df_issuePUTF(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing df_issuePUTF\n");
    try {
       {
    std::shared_ptr<RequestMsg> out_msg = std::make_shared<RequestMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceRequestType_PUTF;
    (*out_msg).m_Requestor = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Writeback_Control;
    ((*m_requestFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_issue_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:df_issuePUTF: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from cache to requestor */
void
L1Cache_Controller::e_sendData(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing e_sendData\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_cache_entry_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:684: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_DataBlk = (*m_cache_entry_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_cache_entry_ptr).m_Dirty;
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:e_sendData: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from cache to requestor, remaining the owner */
void
L1Cache_Controller::ee_sendDataShared(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ee_sendDataShared\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_cache_entry_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:707: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_DataBlk = (*m_cache_entry_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_cache_entry_ptr).m_Dirty;
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:714: %s\n", (*out_msg).m_DataBlk);
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ee_sendDataShared: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from TBE to requestor, keep a shared copy */
void
L1Cache_Controller::et_sendDataSharedFromTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing et_sendDataSharedFromTBE\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:731: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:738: %s\n", (*out_msg).m_DataBlk);
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:et_sendDataSharedFromTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from cache to all requestors, still the owner */
void
L1Cache_Controller::em_sendDataSharedMultiple(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing em_sendDataSharedMultiple\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_cache_entry_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:755: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (*out_msg).m_Destination = ((*in_msg_ptr)).m_MergedRequestors;
    (*out_msg).m_DataBlk = (*m_cache_entry_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_cache_entry_ptr).m_Dirty;
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:762: %s\n", (*out_msg).m_DataBlk);
    (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
    (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
    (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
    (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
    (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
    ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:em_sendDataSharedMultiple: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from tbe to all requestors */
void
L1Cache_Controller::emt_sendDataSharedMultipleFromTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing emt_sendDataSharedMultipleFromTBE\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:775: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (*out_msg).m_Destination = ((*in_msg_ptr)).m_MergedRequestors;
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:782: %s\n", (*out_msg).m_DataBlk);
    (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
    (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
    (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
    (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
    (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
    ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:emt_sendDataSharedMultipleFromTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send ack from cache to requestor */
void
L1Cache_Controller::f_sendAck(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing f_sendAck\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_ACK;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_Acks = (1);
    (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
    #ifndef NDEBUG
    if (!((((*in_msg_ptr)).m_DirectedProbe == (false)))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:801: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_MessageSize = MessageSizeType_Response_Control;
    (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
    (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
    ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:f_sendAck: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send shared ack from cache to requestor */
void
L1Cache_Controller::ff_sendAckShared(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ff_sendAckShared\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_ACK_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    (*out_msg).m_Acks = (1);
    (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
    #ifndef NDEBUG
    if (!((((*in_msg_ptr)).m_DirectedProbe == (false)))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:818: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_MessageSize = MessageSizeType_Response_Control;
    (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
    (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
    ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ff_sendAckShared: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send unblock to memory */
void
L1Cache_Controller::g_sendUnblock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing g_sendUnblock\n");
    try {
       {
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_UNBLOCK;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Unblock_Control;
    ((*m_unblockFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:g_sendUnblock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send unblock to memory and indicate M/O/E state */
void
L1Cache_Controller::gm_sendUnblockM(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing gm_sendUnblockM\n");
    try {
       {
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_UNBLOCKM;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Unblock_Control;
    ((*m_unblockFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:gm_sendUnblockM: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send unblock to memory and indicate S state */
void
L1Cache_Controller::gs_sendUnblockS(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing gs_sendUnblockS\n");
    try {
       {
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:848: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_UNBLOCKS;
    (*out_msg).m_Sender = m_machineID;
    (*out_msg).m_CurOwner = (*m_tbe_ptr).m_CurOwner;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_MessageSize = MessageSizeType_Unblock_Control;
    ((*m_unblockFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:gs_sendUnblockS: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Notify sequencer the load completed. */
void
L1Cache_Controller::h_load_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing h_load_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:859: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:860: %s\n", (*m_cache_entry_ptr).m_DataBlk);
(((*m_L1Dcache_ptr)).setMRU(m_cache_entry_ptr));
(((*m_sequencer_ptr)).readCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (false), (testAndClearLocalHit(m_cache_entry_ptr))));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:h_load_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Notify sequencer the ifetch completed. */
void
L1Cache_Controller::h_ifetch_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing h_ifetch_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:867: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:868: %s\n", (*m_cache_entry_ptr).m_DataBlk);
(((*m_L1Icache_ptr)).setMRU(m_cache_entry_ptr));
(((*m_sequencer_ptr)).readCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (false), (testAndClearLocalHit(m_cache_entry_ptr))));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:h_ifetch_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief load required external msgs */
void
L1Cache_Controller::hx_external_load_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing hx_external_load_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:875: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:876: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:877: %s\n", (*m_cache_entry_ptr).m_DataBlk);
{
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
(((*m_L1Icache_ptr)).setMRU(addr));
(((*m_L1Dcache_ptr)).setMRU(addr));
(((*m_sequencer_ptr)).readCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (true), (machineIDToMachineType(((*in_msg_ptr)).m_Sender)), (*m_tbe_ptr).m_InitialRequestTime, (*m_tbe_ptr).m_ForwardRequestTime, (*m_tbe_ptr).m_FirstResponseTime));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:hx_external_load_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Notify sequencer that store completed. */
void
L1Cache_Controller::hh_store_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing hh_store_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:888: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:889: %s\n", (*m_cache_entry_ptr).m_DataBlk);
{
    // Declare message
    [[maybe_unused]] const RubyRequest* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RubyRequest *>(((*m_mandatoryQueue_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
(((*m_L1Dcache_ptr)).setMRU(m_cache_entry_ptr));
(((*m_sequencer_ptr)).writeCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (false), (testAndClearLocalHit(m_cache_entry_ptr))));
(*m_cache_entry_ptr).m_Dirty = (true);
    if ((((*in_msg_ptr)).m_Type == RubyRequestType_ATOMIC)) {
        (*m_cache_entry_ptr).m_AtomicAccessed = (true);
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:hh_store_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Notify sequencer that flush completed. */
void
L1Cache_Controller::hh_flush_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing hh_flush_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:903: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:904: %s\n", (*m_tbe_ptr).m_DataBlk);
(((*m_sequencer_ptr)).writeCallback(addr, (*m_tbe_ptr).m_DataBlk, (false), MachineType_L1Cache));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:hh_flush_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief store required external msgs. */
void
L1Cache_Controller::sx_external_store_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sx_external_store_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:909: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:910: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:911: %s\n", (*m_cache_entry_ptr).m_DataBlk);
{
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
(((*m_L1Icache_ptr)).setMRU(addr));
(((*m_L1Dcache_ptr)).setMRU(addr));
(((*m_sequencer_ptr)).writeCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (true), (machineIDToMachineType(((*in_msg_ptr)).m_Sender)), (*m_tbe_ptr).m_InitialRequestTime, (*m_tbe_ptr).m_ForwardRequestTime, (*m_tbe_ptr).m_FirstResponseTime));
}
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:919: %s\n", (*m_cache_entry_ptr).m_DataBlk);
(*m_cache_entry_ptr).m_Dirty = (true);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:sx_external_store_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief store required external msgs. */
void
L1Cache_Controller::sxt_trig_ext_store_hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sxt_trig_ext_store_hit\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:924: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:925: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:926: %s\n", (*m_cache_entry_ptr).m_DataBlk);
(((*m_L1Icache_ptr)).setMRU(addr));
(((*m_L1Dcache_ptr)).setMRU(addr));
(((*m_sequencer_ptr)).writeCallback(addr, (*m_cache_entry_ptr).m_DataBlk, (true), (machineIDToMachineType((*m_tbe_ptr).m_LastResponder)), (*m_tbe_ptr).m_InitialRequestTime, (*m_tbe_ptr).m_ForwardRequestTime, (*m_tbe_ptr).m_FirstResponseTime));
(*m_cache_entry_ptr).m_Dirty = (true);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:sxt_trig_ext_store_hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Allocate TBE */
void
L1Cache_Controller::i_allocateTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing i_allocateTBE\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:938: %s.\n", "assert failure");

}
#endif
;
(((*m_TBEs_ptr)).allocate(addr));
set_tbe(m_tbe_ptr, (((*m_TBEs_ptr)).lookup(addr)));;
(*m_tbe_ptr).m_DataBlk = (*m_cache_entry_ptr).m_DataBlk;
(*m_tbe_ptr).m_Dirty = (*m_cache_entry_ptr).m_Dirty;
(*m_tbe_ptr).m_Sharers = (false);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:i_allocateTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Allocate TBE */
void
L1Cache_Controller::it_allocateTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing it_allocateTBE\n");
    try {
       (((*m_TBEs_ptr)).allocate(addr));
set_tbe(m_tbe_ptr, (((*m_TBEs_ptr)).lookup(addr)));;
(*m_tbe_ptr).m_Dirty = (false);
(*m_tbe_ptr).m_Sharers = (false);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:it_allocateTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Pop trigger queue. */
void
L1Cache_Controller::j_popTriggerQueue(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing j_popTriggerQueue\n");
    try {
       (((*m_triggerQueue_ptr)).dequeue((clockEdge())));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:j_popTriggerQueue: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Pop mandatory queue. */
void
L1Cache_Controller::k_popMandatoryQueue(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing k_popMandatoryQueue\n");
    try {
       (((*m_mandatoryQueue_ptr)).dequeue((clockEdge())));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:k_popMandatoryQueue: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Pop forwareded request queue. */
void
L1Cache_Controller::l_popForwardQueue(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing l_popForwardQueue\n");
    try {
       (((*m_forwardToCache_ptr)).dequeue((clockEdge())));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:l_popForwardQueue: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Copy data from TBE to L2 cache entry. */
void
L1Cache_Controller::hp_copyFromTBEToL2(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing hp_copyFromTBEToL2\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:967: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:968: %s.\n", "assert failure");

}
#endif
;
(*m_cache_entry_ptr).m_Dirty = (*m_tbe_ptr).m_Dirty;
(*m_cache_entry_ptr).m_DataBlk = (*m_tbe_ptr).m_DataBlk;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:hp_copyFromTBEToL2: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Copy data from TBE to L1 cache entry. */
void
L1Cache_Controller::nb_copyFromTBEToL1(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing nb_copyFromTBEToL1\n");
    try {
       #ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:974: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:975: %s.\n", "assert failure");

}
#endif
;
(*m_cache_entry_ptr).m_Dirty = (*m_tbe_ptr).m_Dirty;
(*m_cache_entry_ptr).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
(*m_cache_entry_ptr).m_FromL2 = (true);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:nb_copyFromTBEToL1: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Decrement the number of messages for which we're waiting */
void
L1Cache_Controller::m_decrementNumberOfMessages(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing m_decrementNumberOfMessages\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((((*in_msg_ptr)).m_Acks >= (0)))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:983: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:984: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:985: Sender = %s\n", ((*in_msg_ptr)).m_Sender);
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:986: SilentAcks = %d\n", ((*in_msg_ptr)).m_SilentAcks);
    if (((*m_tbe_ptr).m_AppliedSilentAcks == (false))) {
        (*m_tbe_ptr).m_NumPendingMsgs = ((*m_tbe_ptr).m_NumPendingMsgs - ((*in_msg_ptr)).m_SilentAcks);
        (*m_tbe_ptr).m_AppliedSilentAcks = (true);
    }
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:991: %d\n", (*m_tbe_ptr).m_NumPendingMsgs);
    (*m_tbe_ptr).m_NumPendingMsgs = ((*m_tbe_ptr).m_NumPendingMsgs - ((*in_msg_ptr)).m_Acks);
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:993: %d\n", (*m_tbe_ptr).m_NumPendingMsgs);
    APPEND_TRANSITION_COMMENT((*m_tbe_ptr).m_NumPendingMsgs);
    APPEND_TRANSITION_COMMENT(((*in_msg_ptr)).m_Sender);
    (*m_tbe_ptr).m_LastResponder = ((*in_msg_ptr)).m_Sender;
        if ((((*m_tbe_ptr).m_InitialRequestTime != (zero_time())) && (((*in_msg_ptr)).m_InitialRequestTime != (zero_time())))) {
            #ifndef NDEBUG
            if (!(((*m_tbe_ptr).m_InitialRequestTime == ((*in_msg_ptr)).m_InitialRequestTime))) {
                panic("Runtime Error at MOESI_hammer-cache.sm:998: %s.\n", "assert failure");

            }
            #endif
            ;
        }
            if ((((*in_msg_ptr)).m_InitialRequestTime != (zero_time()))) {
                (*m_tbe_ptr).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
            }
                if ((((*m_tbe_ptr).m_ForwardRequestTime != (zero_time())) && (((*in_msg_ptr)).m_ForwardRequestTime != (zero_time())))) {
                    #ifndef NDEBUG
                    if (!(((*m_tbe_ptr).m_ForwardRequestTime == ((*in_msg_ptr)).m_ForwardRequestTime))) {
                        panic("Runtime Error at MOESI_hammer-cache.sm:1004: %s.\n", "assert failure");

                    }
                    #endif
                    ;
                }
                    if ((((*in_msg_ptr)).m_ForwardRequestTime != (zero_time()))) {
                        (*m_tbe_ptr).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
                    }
                        if (((*m_tbe_ptr).m_FirstResponseTime == (zero_time()))) {
                            (*m_tbe_ptr).m_FirstResponseTime = (curCycle());
                        }
                        }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:m_decrementNumberOfMessages: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief When moving SS state, update current owner. */
void
L1Cache_Controller::uo_updateCurrentOwner(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uo_updateCurrentOwner\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1016: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_CurOwner = ((*in_msg_ptr)).m_Sender;
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uo_updateCurrentOwner: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Pop response queue */
void
L1Cache_Controller::n_popResponseQueue(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing n_popResponseQueue\n");
    try {
       (((*m_responseToCache_ptr)).dequeue((clockEdge())));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:n_popResponseQueue: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief  */
void
L1Cache_Controller::ll_L2toL1Transfer(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ll_L2toL1Transfer\n");
    try {
       {
    std::shared_ptr<TriggerMsg> out_msg = std::make_shared<TriggerMsg>(clockEdge());
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = TriggerType_L2_to_L1;
    ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_l2_cache_hit_latency)));
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ll_L2toL1Transfer: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Check if we have received all the messages required for completion */
void
L1Cache_Controller::o_checkForCompletion(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing o_checkForCompletion\n");
    try {
       #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1033: %s.\n", "assert failure");

}
#endif
;
    if (((*m_tbe_ptr).m_NumPendingMsgs == (0))) {
        {
            std::shared_ptr<TriggerMsg> out_msg = std::make_shared<TriggerMsg>(clockEdge());
            (*out_msg).m_addr = addr;
                if ((*m_tbe_ptr).m_Sharers) {
                    (*out_msg).m_Type = TriggerType_ALL_ACKS;
                } else {
                    (*out_msg).m_Type = TriggerType_ALL_ACKS_NO_SHARERS;
                }
                ((*m_triggerQueue_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(1)));
            }
        }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:o_checkForCompletion: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Decrement the number of messages for which we're waiting by one */
void
L1Cache_Controller::p_decrementNumberOfMessagesByOne(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing p_decrementNumberOfMessagesByOne\n");
    try {
       #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1047: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_NumPendingMsgs = ((*m_tbe_ptr).m_NumPendingMsgs - (1));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:p_decrementNumberOfMessagesByOne: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Increment the number of messages for which we're waiting by one */
void
L1Cache_Controller::pp_incrementNumberOfMessagesByOne(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing pp_incrementNumberOfMessagesByOne\n");
    try {
       #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1052: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_NumPendingMsgs = ((*m_tbe_ptr).m_NumPendingMsgs + (1));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:pp_incrementNumberOfMessagesByOne: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from TBE to cache */
void
L1Cache_Controller::q_sendDataFromTBEToCache(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing q_sendDataFromTBEToCache\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((((*in_msg_ptr)).m_Requestor != m_machineID))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1058: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:1060: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1065: %s\n", (*out_msg).m_Destination);
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:q_sendDataFromTBEToCache: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send shared data from TBE to cache, still the owner */
void
L1Cache_Controller::sq_sendSharedDataFromTBEToCache(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing sq_sendSharedDataFromTBEToCache\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((((*in_msg_ptr)).m_Requestor != m_machineID))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1083: %s.\n", "assert failure");

}
#endif
;
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:1085: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add(((*in_msg_ptr)).m_Requestor));
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1090: %s\n", (*out_msg).m_Destination);
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
        if (((*in_msg_ptr)).m_DirectedProbe) {
            (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
        } else {
            (*out_msg).m_Acks = (2);
        }
        (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
        (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
        (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
        (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
        ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:sq_sendSharedDataFromTBEToCache: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from TBE to cache, multiple sharers, still the owner */
void
L1Cache_Controller::qm_sendDataFromTBEToCache(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing qm_sendDataFromTBEToCache\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const RequestMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const RequestMsg *>(((*m_forwardToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
{
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:1109: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Type = CoherenceResponseType_DATA_SHARED;
    (*out_msg).m_Sender = m_machineID;
    (*out_msg).m_Destination = ((*in_msg_ptr)).m_MergedRequestors;
    DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1114: %s\n", (*out_msg).m_Destination);
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
    (*out_msg).m_Acks = (machineCount(MachineType_L1Cache));
    (*out_msg).m_SilentAcks = ((*in_msg_ptr)).m_SilentAcks;
    (*out_msg).m_MessageSize = MessageSizeType_Response_Data;
    (*out_msg).m_InitialRequestTime = ((*in_msg_ptr)).m_InitialRequestTime;
    (*out_msg).m_ForwardRequestTime = ((*in_msg_ptr)).m_ForwardRequestTime;
    ((*m_responseFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
}
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:qm_sendDataFromTBEToCache: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send data from TBE to memory */
void
L1Cache_Controller::qq_sendDataFromTBEToMemory(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing qq_sendDataFromTBEToMemory\n");
    try {
       {
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:1128: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
        if ((*m_tbe_ptr).m_Dirty) {
            (*out_msg).m_Type = CoherenceResponseType_WB_DIRTY;
            (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
            (*out_msg).m_MessageSize = MessageSizeType_Writeback_Data;
        } else {
            (*out_msg).m_Type = CoherenceResponseType_WB_CLEAN;
            (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
            (*out_msg).m_MessageSize = MessageSizeType_Writeback_Control;
        }
        ((*m_unblockFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:qq_sendDataFromTBEToMemory: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief We saw other sharers */
void
L1Cache_Controller::r_setSharerBit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing r_setSharerBit\n");
    try {
       #ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1148: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_Sharers = (true);

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:r_setSharerBit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Deallocate TBE */
void
L1Cache_Controller::s_deallocateTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing s_deallocateTBE\n");
    try {
       (((*m_TBEs_ptr)).deallocate(addr));
unset_tbe(m_tbe_ptr);;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:s_deallocateTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send exclusive data from TBE to memory */
void
L1Cache_Controller::t_sendExclusiveDataFromTBEToMemory(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing t_sendExclusiveDataFromTBEToMemory\n");
    try {
       {
    std::shared_ptr<ResponseMsg> out_msg = std::make_shared<ResponseMsg>(clockEdge());
    #ifndef NDEBUG
    if (!((m_tbe_ptr != NULL))) {
        panic("Runtime Error at MOESI_hammer-cache.sm:1159: %s.\n", "assert failure");

    }
    #endif
    ;
    (*out_msg).m_addr = addr;
    (*out_msg).m_Sender = m_machineID;
    (((*out_msg).m_Destination).add((mapAddressToMachine(addr, MachineType_Directory))));
    (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
    (*out_msg).m_Dirty = (*m_tbe_ptr).m_Dirty;
        if ((*m_tbe_ptr).m_Dirty) {
            (*out_msg).m_Type = CoherenceResponseType_WB_EXCLUSIVE_DIRTY;
            (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
            (*out_msg).m_MessageSize = MessageSizeType_Writeback_Data;
        } else {
            (*out_msg).m_Type = CoherenceResponseType_WB_EXCLUSIVE_CLEAN;
            (*out_msg).m_DataBlk = (*m_tbe_ptr).m_DataBlk;
            (*out_msg).m_MessageSize = MessageSizeType_Writeback_Control;
        }
        ((*m_unblockFromCache_ptr)).enqueue(out_msg, clockEdge(), cyclesToTicks(Cycles(m_cache_response_latency)));
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:t_sendExclusiveDataFromTBEToMemory: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Write data to cache */
void
L1Cache_Controller::u_writeDataToCache(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing u_writeDataToCache\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1181: %s.\n", "assert failure");

}
#endif
;
(*m_cache_entry_ptr).m_DataBlk = ((*in_msg_ptr)).m_DataBlk;
(*m_cache_entry_ptr).m_Dirty = ((*in_msg_ptr)).m_Dirty;
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:u_writeDataToCache: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Write data to TBE */
void
L1Cache_Controller::uf_writeDataToCacheTBE(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uf_writeDataToCacheTBE\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1189: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_DataBlk = ((*in_msg_ptr)).m_DataBlk;
(*m_tbe_ptr).m_Dirty = ((*in_msg_ptr)).m_Dirty;
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uf_writeDataToCacheTBE: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Write data to cache, assert it was same as before */
void
L1Cache_Controller::v_writeDataToCacheVerify(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing v_writeDataToCacheVerify\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_cache_entry_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1197: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1198: Cached Data Block: %s, Msg Data Block: %s\n", (*m_cache_entry_ptr).m_DataBlk, ((*in_msg_ptr)).m_DataBlk);
#ifndef NDEBUG
if (!(((*m_cache_entry_ptr).m_DataBlk == ((*in_msg_ptr)).m_DataBlk))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1200: %s.\n", "assert failure");

}
#endif
;
(*m_cache_entry_ptr).m_DataBlk = ((*in_msg_ptr)).m_DataBlk;
(*m_cache_entry_ptr).m_Dirty = (((*in_msg_ptr)).m_Dirty || (*m_cache_entry_ptr).m_Dirty);
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:v_writeDataToCacheVerify: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Write data to TBE, assert it was same as before */
void
L1Cache_Controller::vt_writeDataToTBEVerify(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing vt_writeDataToTBEVerify\n");
    try {
       {
    // Declare message
    [[maybe_unused]] const ResponseMsg* in_msg_ptr;
    in_msg_ptr = dynamic_cast<const ResponseMsg *>(((*m_responseToCache_ptr)).peek());
    if (in_msg_ptr == NULL) {
        // If the cast fails, this is the wrong inport (wrong message type).
        // Throw an exception, and the caller will decide to either try a
        // different inport or punt.
        throw RejectException();
    }
#ifndef NDEBUG
if (!((m_tbe_ptr != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1208: %s.\n", "assert failure");

}
#endif
;
DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1209: Cached Data Block: %s, Msg Data Block: %s\n", (*m_tbe_ptr).m_DataBlk, ((*in_msg_ptr)).m_DataBlk);
#ifndef NDEBUG
if (!(((*m_tbe_ptr).m_DataBlk == ((*in_msg_ptr)).m_DataBlk))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:1211: %s.\n", "assert failure");

}
#endif
;
(*m_tbe_ptr).m_DataBlk = ((*in_msg_ptr)).m_DataBlk;
(*m_tbe_ptr).m_Dirty = (((*in_msg_ptr)).m_Dirty || (*m_tbe_ptr).m_Dirty);
}

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:vt_writeDataToTBEVerify: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Deallocate cache block.  Sets the cache to invalid, allowing a replacement in parallel with a fetch. */
void
L1Cache_Controller::gg_deallocateL1CacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing gg_deallocateL1CacheBlock\n");
    try {
           if ((((*m_L1Dcache_ptr)).isTagPresent(addr))) {
        (((*m_L1Dcache_ptr)).deallocate(addr));
    } else {
        (((*m_L1Icache_ptr)).deallocate(addr));
    }
    unset_cache_entry(m_cache_entry_ptr);;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:gg_deallocateL1CacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Set L1 D-cache tag equal to tag of block B. */
void
L1Cache_Controller::ii_allocateL1DCacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ii_allocateL1DCacheBlock\n");
    try {
           if ((m_cache_entry_ptr == NULL)) {
        set_cache_entry(m_cache_entry_ptr, (((*m_L1Dcache_ptr)).allocate(addr, new L1Cache_Entry)));;
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ii_allocateL1DCacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Set L1 I-cache tag equal to tag of block B. */
void
L1Cache_Controller::jj_allocateL1ICacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing jj_allocateL1ICacheBlock\n");
    try {
           if ((m_cache_entry_ptr == NULL)) {
        set_cache_entry(m_cache_entry_ptr, (((*m_L1Icache_ptr)).allocate(addr, new L1Cache_Entry)));;
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:jj_allocateL1ICacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Set L2 cache tag equal to tag of block B. */
void
L1Cache_Controller::vv_allocateL2CacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing vv_allocateL2CacheBlock\n");
    try {
       set_cache_entry(m_cache_entry_ptr, (((*m_L2cache_ptr)).allocate(addr, new L1Cache_Entry)));;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:vv_allocateL2CacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Deallocate L2 cache block.  Sets the cache to not present, allowing a replacement in parallel with a fetch. */
void
L1Cache_Controller::rr_deallocateL2CacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing rr_deallocateL2CacheBlock\n");
    try {
       (((*m_L2cache_ptr)).deallocate(addr));
unset_cache_entry(m_cache_entry_ptr);;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:rr_deallocateL2CacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Deallocate an L1 or L2 cache block. */
void
L1Cache_Controller::gr_deallocateCacheBlock(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing gr_deallocateCacheBlock\n");
    try {
           if ((((*m_L1Dcache_ptr)).isTagPresent(addr))) {
        (((*m_L1Dcache_ptr)).deallocate(addr));
    } else {
            if ((((*m_L1Icache_ptr)).isTagPresent(addr))) {
                (((*m_L1Icache_ptr)).deallocate(addr));
            } else {
                #ifndef NDEBUG
                if (!((((*m_L2cache_ptr)).isTagPresent(addr)))) {
                    panic("Runtime Error at MOESI_hammer-cache.sm:1255: %s.\n", "assert failure");

                }
                #endif
                ;
                (((*m_L2cache_ptr)).deallocate(addr));
            }
        }
        unset_cache_entry(m_cache_entry_ptr);;

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:gr_deallocateCacheBlock: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief sends eviction information to the processor */
void
L1Cache_Controller::forward_eviction_to_cpu(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing forward_eviction_to_cpu\n");
    try {
           if (m_send_evictions) {
        DPRINTF(RubySlicc, "MOESI_hammer-cache.sm:1263: Sending invalidation for %#x to the CPU\n", addr);
        (((*m_sequencer_ptr)).evictionCallback(addr));
    }

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:forward_eviction_to_cpu: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand miss */
void
L1Cache_Controller::uu_profileL1DataMiss(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL1DataMiss\n");
    try {
       (((*m_L1Dcache_ptr)).profileDemandMiss());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL1DataMiss: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand hits */
void
L1Cache_Controller::uu_profileL1DataHit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL1DataHit\n");
    try {
       (((*m_L1Dcache_ptr)).profileDemandHit());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL1DataHit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand miss */
void
L1Cache_Controller::uu_profileL1InstMiss(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL1InstMiss\n");
    try {
       (((*m_L1Icache_ptr)).profileDemandMiss());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL1InstMiss: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand hits */
void
L1Cache_Controller::uu_profileL1InstHit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL1InstHit\n");
    try {
       (((*m_L1Icache_ptr)).profileDemandHit());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL1InstHit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand miss */
void
L1Cache_Controller::uu_profileL2Miss(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL2Miss\n");
    try {
       (((*m_L2cache_ptr)).profileDemandMiss());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL2Miss: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Profile the demand hits */
void
L1Cache_Controller::uu_profileL2Hit(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing uu_profileL2Hit\n");
    try {
       (((*m_L2cache_ptr)).profileDemandHit());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:uu_profileL2Hit: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief Send the head of the mandatory queue to the back of the queue. */
void
L1Cache_Controller::zz_stallAndWaitMandatoryQueue(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing zz_stallAndWaitMandatoryQueue\n");
    try {
               stallBuffer(&((*m_mandatoryQueue_ptr)), addr);
        (*m_mandatoryQueue_ptr).stallMessage(addr, clockEdge());
        

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:zz_stallAndWaitMandatoryQueue: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief stall */
void
L1Cache_Controller::z_stall(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing z_stall\n");
    try {
       
    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:z_stall: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief wake-up dependents */
void
L1Cache_Controller::kd_wakeUpDependents(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing kd_wakeUpDependents\n");
    try {
       (wakeUpBuffers(addr));

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:kd_wakeUpDependents: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

/** \brief wake-up all dependents */
void
L1Cache_Controller::ka_wakeUpAllDependents(L1Cache_TBE*& m_tbe_ptr, L1Cache_Entry*& m_cache_entry_ptr, Addr addr)
{
    DPRINTF(RubyGenerated, "executing ka_wakeUpAllDependents\n");
    try {
       (wakeUpAllBuffers());

    } catch (const RejectException & e) {
       fatal("Error in action L1Cache:ka_wakeUpAllDependents: "
             "executed a peek statement with the wrong message "
             "type specified. ");
    }
}

L1Cache_Entry*
L1Cache_Controller::getCacheEntry(const Addr& param_address)
{
L1Cache_Entry* L2cache_entry
 = static_cast<L1Cache_Entry *>((((*m_L2cache_ptr)).lookup(param_address)))
;
    if ((L2cache_entry != NULL)) {
        return L2cache_entry;
    }
    L1Cache_Entry* L1Dcache_entry
     = static_cast<L1Cache_Entry *>((((*m_L1Dcache_ptr)).lookup(param_address)))
    ;
        if ((L1Dcache_entry != NULL)) {
            return L1Dcache_entry;
        }
        L1Cache_Entry* L1Icache_entry
         = static_cast<L1Cache_Entry *>((((*m_L1Icache_ptr)).lookup(param_address)))
        ;
        return L1Icache_entry;

}
void
L1Cache_Controller::functionalRead(const Addr& param_addr, Packet* param_pkt)
{
L1Cache_Entry* cache_entry
 = (getCacheEntry(param_addr));
    if ((cache_entry != NULL)) {
        (testAndRead(param_addr, (*cache_entry).m_DataBlk, param_pkt));
    } else {
        L1Cache_TBE* tbe
         = (((*m_TBEs_ptr)).lookup(param_addr));
            if ((tbe != NULL)) {
                (testAndRead(param_addr, (*tbe).m_DataBlk, param_pkt));
            } else {
                panic("Runtime Error at MOESI_hammer-cache.sm:214: %s.\n", ("Missing data block"));
                ;
            }
        }

}
int
L1Cache_Controller::functionalWrite(const Addr& param_addr, Packet* param_pkt)
{
int num_functional_writes
 = (0);
L1Cache_Entry* cache_entry
 = (getCacheEntry(param_addr));
    if ((cache_entry != NULL)) {
        num_functional_writes = (num_functional_writes + (testAndWrite(param_addr, (*cache_entry).m_DataBlk, param_pkt)));
        return num_functional_writes;
    }
    L1Cache_TBE* tbe
     = (((*m_TBEs_ptr)).lookup(param_addr));
    num_functional_writes = (num_functional_writes + (testAndWrite(param_addr, (*tbe).m_DataBlk, param_pkt)));
    return num_functional_writes;

}
L1Cache_Entry*
L1Cache_Controller::getL2CacheEntry(const Addr& param_address)
{
L1Cache_Entry* L2cache_entry
 = static_cast<L1Cache_Entry *>((((*m_L2cache_ptr)).lookup(param_address)))
;
return L2cache_entry;

}
L1Cache_Entry*
L1Cache_Controller::getL1DCacheEntry(const Addr& param_address)
{
L1Cache_Entry* L1Dcache_entry
 = static_cast<L1Cache_Entry *>((((*m_L1Dcache_ptr)).lookup(param_address)))
;
return L1Dcache_entry;

}
L1Cache_Entry*
L1Cache_Controller::getL1ICacheEntry(const Addr& param_address)
{
L1Cache_Entry* L1Icache_entry
 = static_cast<L1Cache_Entry *>((((*m_L1Icache_ptr)).lookup(param_address)))
;
return L1Icache_entry;

}
L1Cache_State
L1Cache_Controller::getState(L1Cache_TBE* param_tbe, L1Cache_Entry* param_cache_entry, const Addr& param_addr)
{
    if ((param_tbe != NULL)) {
        return (*param_tbe).m_TBEState;
    } else {
            if ((param_cache_entry != NULL)) {
                return (*param_cache_entry).m_CacheState;
            }
        }
        return L1Cache_State_I;

}
void
L1Cache_Controller::setState(L1Cache_TBE* param_tbe, L1Cache_Entry* param_cache_entry, const Addr& param_addr, const L1Cache_State& param_state)
{
#ifndef NDEBUG
if (!((((((*m_L1Dcache_ptr)).isTagPresent(param_addr)) && (((*m_L1Icache_ptr)).isTagPresent(param_addr))) == (false)))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:260: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((((((*m_L1Icache_ptr)).isTagPresent(param_addr)) && (((*m_L2cache_ptr)).isTagPresent(param_addr))) == (false)))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:261: %s.\n", "assert failure");

}
#endif
;
#ifndef NDEBUG
if (!((((((*m_L1Dcache_ptr)).isTagPresent(param_addr)) && (((*m_L2cache_ptr)).isTagPresent(param_addr))) == (false)))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:262: %s.\n", "assert failure");

}
#endif
;
    if ((param_tbe != NULL)) {
        (*param_tbe).m_TBEState = param_state;
    }
        if ((param_cache_entry != NULL)) {
            (*param_cache_entry).m_CacheState = param_state;
        }

}
AccessPermission
L1Cache_Controller::getAccessPermission(const Addr& param_addr)
{
L1Cache_TBE* tbe
 = (((*m_TBEs_ptr)).lookup(param_addr));
    if ((tbe != NULL)) {
        return (L1Cache_State_to_permission((*tbe).m_TBEState));
    }
    L1Cache_Entry* cache_entry
     = (getCacheEntry(param_addr));
        if ((cache_entry != NULL)) {
            return (L1Cache_State_to_permission((*cache_entry).m_CacheState));
        }
        return AccessPermission_NotPresent;

}
void
L1Cache_Controller::setAccessPermission(L1Cache_Entry* param_cache_entry, const Addr& param_addr, const L1Cache_State& param_state)
{
    if ((param_cache_entry != NULL)) {
        ((*(param_cache_entry)).changePermission((L1Cache_State_to_permission(param_state))));
    }

}
L1Cache_Event
L1Cache_Controller::mandatory_request_type_to_event(const RubyRequestType& param_type)
{
    if ((param_type == RubyRequestType_LD)) {
        return L1Cache_Event_Load;
    } else {
            if ((param_type == RubyRequestType_IFETCH)) {
                return L1Cache_Event_Ifetch;
            } else {
                    if (((param_type == RubyRequestType_ST) || (param_type == RubyRequestType_ATOMIC))) {
                        return L1Cache_Event_Store;
                    } else {
                            if ((param_type == RubyRequestType_FLUSH)) {
                                return L1Cache_Event_Flush_line;
                            } else {
                                panic("Runtime Error at MOESI_hammer-cache.sm:303: %s.\n", ("Invalid RubyRequestType"));
                                ;
                            }
                        }
                    }
                }

}
MachineType
L1Cache_Controller::testAndClearLocalHit(L1Cache_Entry* param_cache_entry)
{
    if (((param_cache_entry != NULL) && (*param_cache_entry).m_FromL2)) {
        (*param_cache_entry).m_FromL2 = (false);
        return MachineType_L2Cache;
    }
    return MachineType_L1Cache;

}
bool
L1Cache_Controller::IsAtomicAccessed(L1Cache_Entry* param_cache_entry)
{
#ifndef NDEBUG
if (!((param_cache_entry != NULL))) {
    panic("Runtime Error at MOESI_hammer-cache.sm:316: %s.\n", "assert failure");

}
#endif
;
return (*param_cache_entry).m_AtomicAccessed;

}
int
L1Cache_Controller::functionalWriteBuffers(PacketPtr& pkt)
{
    int num_functional_writes = 0;
num_functional_writes += m_requestFromCache_ptr->functionalWrite(pkt);
num_functional_writes += m_responseFromCache_ptr->functionalWrite(pkt);
num_functional_writes += m_unblockFromCache_ptr->functionalWrite(pkt);
num_functional_writes += m_forwardToCache_ptr->functionalWrite(pkt);
num_functional_writes += m_responseToCache_ptr->functionalWrite(pkt);
num_functional_writes += m_mandatoryQueue_ptr->functionalWrite(pkt);
num_functional_writes += m_triggerQueue_ptr->functionalWrite(pkt);
    return num_functional_writes;
}
bool
L1Cache_Controller::functionalReadBuffers(PacketPtr& pkt)
{
if (m_requestFromCache_ptr->functionalRead(pkt)) return true;
if (m_responseFromCache_ptr->functionalRead(pkt)) return true;
if (m_unblockFromCache_ptr->functionalRead(pkt)) return true;
if (m_forwardToCache_ptr->functionalRead(pkt)) return true;
if (m_responseToCache_ptr->functionalRead(pkt)) return true;
if (m_mandatoryQueue_ptr->functionalRead(pkt)) return true;
if (m_triggerQueue_ptr->functionalRead(pkt)) return true;
    return false;
}

bool
L1Cache_Controller::functionalReadBuffers(PacketPtr& pkt, WriteMask &mask)
{
    bool read = false;
if (m_requestFromCache_ptr->functionalRead(pkt, mask)) read = true;
if (m_responseFromCache_ptr->functionalRead(pkt, mask)) read = true;
if (m_unblockFromCache_ptr->functionalRead(pkt, mask)) read = true;
if (m_forwardToCache_ptr->functionalRead(pkt, mask)) read = true;
if (m_responseToCache_ptr->functionalRead(pkt, mask)) read = true;
if (m_mandatoryQueue_ptr->functionalRead(pkt, mask)) read = true;
if (m_triggerQueue_ptr->functionalRead(pkt, mask)) read = true;
    return read;
}

} // namespace ruby
} // namespace gem5
