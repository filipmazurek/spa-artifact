/**
 * DO NOT EDIT THIS FILE!
 * File automatically generated by
 *   /shared/gem5/src/mem/slicc/symbols/StateMachine.py:1814
 */

// L1Cache: AMD Hammer-like protocol

#include <cassert>

#include "base/logging.hh"
#include "base/trace.hh"
#include "debug/ProtocolTrace.hh"
#include "debug/RubyGenerated.hh"
#include "mem/ruby/protocol/L1Cache_Controller.hh"
#include "mem/ruby/protocol/L1Cache_Event.hh"
#include "mem/ruby/protocol/L1Cache_State.hh"
#include "mem/ruby/protocol/Types.hh"
#include "mem/ruby/system/RubySystem.hh"

#define HASH_FUN(state, event)  ((int(state)*L1Cache_Event_NUM)+int(event))

#define GET_TRANSITION_COMMENT() (L1Cache_transitionComment.str())
#define CLEAR_TRANSITION_COMMENT() (L1Cache_transitionComment.str(""))

namespace gem5
{

namespace ruby
{

TransitionResult
L1Cache_Controller::doTransition(L1Cache_Event event,
                                  L1Cache_Entry* m_cache_entry_ptr,
                                  L1Cache_TBE* m_tbe_ptr,
                                  Addr addr)
{
    L1Cache_State state = getState(m_tbe_ptr, m_cache_entry_ptr, addr);
    L1Cache_State next_state = state;

    DPRINTF(RubyGenerated, "%s, Time: %lld, state: %s, event: %s, addr: %#x\n",
            *this, curCycle(), L1Cache_State_to_string(state),
            L1Cache_Event_to_string(event), addr);

    TransitionResult result =
    doTransitionWorker(event, state, next_state, m_tbe_ptr, m_cache_entry_ptr, addr);

    if (result == TransitionResult_Valid) {
        DPRINTF(RubyGenerated, "next_state: %s\n",
                L1Cache_State_to_string(next_state));
        countTransition(state, event);

        DPRINTFR(ProtocolTrace, "%15d %3s %10s%20s %6s>%-6s %#x %s\n",
                 curTick(), m_version, "L1Cache",
                 L1Cache_Event_to_string(event),
                 L1Cache_State_to_string(state),
                 L1Cache_State_to_string(next_state),
                 printAddress(addr), GET_TRANSITION_COMMENT());

        CLEAR_TRANSITION_COMMENT();
    setState(m_tbe_ptr, m_cache_entry_ptr, addr, next_state);
    setAccessPermission(m_cache_entry_ptr, addr, next_state);
    } else if (result == TransitionResult_ResourceStall) {
        DPRINTFR(ProtocolTrace, "%15s %3s %10s%20s %6s>%-6s %#x %s\n",
                 curTick(), m_version, "L1Cache",
                 L1Cache_Event_to_string(event),
                 L1Cache_State_to_string(state),
                 L1Cache_State_to_string(next_state),
                 printAddress(addr), "Resource Stall");
    } else if (result == TransitionResult_ProtocolStall) {
        DPRINTF(RubyGenerated, "stalling\n");
        DPRINTFR(ProtocolTrace, "%15s %3s %10s%20s %6s>%-6s %#x %s\n",
                 curTick(), m_version, "L1Cache",
                 L1Cache_Event_to_string(event),
                 L1Cache_State_to_string(state),
                 L1Cache_State_to_string(next_state),
                 printAddress(addr), "Protocol Stall");
    }

    return result;
}

TransitionResult
L1Cache_Controller::doTransitionWorker(L1Cache_Event event,
                                        L1Cache_State state,
                                        L1Cache_State& next_state,
                                        L1Cache_TBE*& m_tbe_ptr,
                                        L1Cache_Entry*& m_cache_entry_ptr,
                                        Addr addr)
{
    m_curTransitionEvent = event;
    m_curTransitionNextState = next_state;
    switch(HASH_FUN(state, event)) {
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_Flush_line):
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Invalidate):
    return TransitionResult_ProtocolStall;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_L1_to_L2):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_L1_to_L2):
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    gg_deallocateL1CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    vv_allocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    hp_copyFromTBEToL2(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Trigger_L2_to_L1D):
    next_state = L1Cache_State_ST; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Trigger_L2_to_L1D):
    next_state = L1Cache_State_OT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Trigger_L2_to_L1D):
    next_state = L1Cache_State_MT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Trigger_L2_to_L1D):
    next_state = L1Cache_State_MMT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Trigger_L2_to_L1I):
    next_state = L1Cache_State_ST; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    jj_allocateL1ICacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Trigger_L2_to_L1I):
    next_state = L1Cache_State_OT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    jj_allocateL1ICacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Trigger_L2_to_L1I):
    next_state = L1Cache_State_MT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    jj_allocateL1ICacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Trigger_L2_to_L1I):
    next_state = L1Cache_State_MMT; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    jj_allocateL1ICacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    nb_copyFromTBEToL1(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    zz_stallAndWaitMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ll_L2toL1Transfer(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_ST, L1Cache_Event_Complete_L2_to_L1):
    next_state = L1Cache_State_SR; m_curTransitionNextState = next_state;
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OT, L1Cache_Event_Complete_L2_to_L1):
    next_state = L1Cache_State_OR; m_curTransitionNextState = next_state;
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MT, L1Cache_Event_Complete_L2_to_L1):
    next_state = L1Cache_State_MR; m_curTransitionNextState = next_state;
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MMT, L1Cache_Event_Complete_L2_to_L1):
    next_state = L1Cache_State_MMR; m_curTransitionNextState = next_state;
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Load):
    next_state = L1Cache_State_IS; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    a_issueGETS(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Miss(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Ifetch):
    next_state = L1Cache_State_IS; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    jj_allocateL1ICacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    a_issueGETS(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Miss(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Store):
    next_state = L1Cache_State_IM; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ii_allocateL1DCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    b_issueGETX(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Miss(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_IR, L1Cache_Event_Flush_line):
    next_state = L1Cache_State_IM_F; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    it_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    bf_issueGETF(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_I, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_I, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Invalidate):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    f_sendAck(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Load):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Load):
    h_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataHit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Ifetch):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Ifetch):
    h_ifetch_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstHit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Load):
    next_state = L1Cache_State_S; m_curTransitionNextState = next_state;
    h_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Ifetch):
    next_state = L1Cache_State_S; m_curTransitionNextState = next_state;
    h_ifetch_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Store):
    next_state = L1Cache_State_SM; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    b_issueGETX(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Miss(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_SR, L1Cache_Event_Flush_line):
    next_state = L1Cache_State_SM_F; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    bf_issueGETF(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gg_deallocateL1CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_L2_Replacement):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    f_sendAck(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gr_deallocateCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_S, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_S, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Other_GETS_No_Mig):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ff_sendAckShared(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Load):
    next_state = L1Cache_State_O; m_curTransitionNextState = next_state;
    h_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Ifetch):
    next_state = L1Cache_State_O; m_curTransitionNextState = next_state;
    h_ifetch_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Store):
    next_state = L1Cache_State_OM; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    b_issueGETX(m_tbe_ptr, m_cache_entry_ptr, addr);
    p_decrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Miss(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_OR, L1Cache_Event_Flush_line):
    next_state = L1Cache_State_OM_F; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    bf_issueGETF(m_tbe_ptr, m_cache_entry_ptr, addr);
    p_decrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gg_deallocateL1CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_L2_Replacement):
    next_state = L1Cache_State_OI; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    d_issuePUT(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    e_sendData(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gr_deallocateCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Other_GETS_No_Mig):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ee_sendDataShared(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_O, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Merged_GETS):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    em_sendDataSharedMultiple(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_Store):
    hh_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataHit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Load):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    h_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Ifetch):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    h_ifetch_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Store):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Store):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    hh_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MMR, L1Cache_Event_Flush_line):
  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Flush_line):
    next_state = L1Cache_State_MM_F; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    bf_issueGETF(m_tbe_ptr, m_cache_entry_ptr, addr);
    p_decrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gg_deallocateL1CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Block_Ack):
    next_state = L1Cache_State_MI_F; m_curTransitionNextState = next_state;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    df_issuePUTF(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_L2_Replacement):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_L2_Replacement):
    next_state = L1Cache_State_MI; m_curTransitionNextState = next_state;
    if (!(*m_TBEs_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    i_allocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    d_issuePUT(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    rr_deallocateL2CacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    c_sendExclusiveData(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    gr_deallocateCacheBlock(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Other_GETS_No_Mig):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_NC_DMA_GETS):
    next_state = L1Cache_State_O; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ee_sendDataShared(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM, L1Cache_Event_Merged_GETS):
  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Merged_GETS):
    next_state = L1Cache_State_O; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    em_sendDataSharedMultiple(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_M, L1Cache_Event_Store):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    hh_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataHit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Load):
    next_state = L1Cache_State_M; m_curTransitionNextState = next_state;
    h_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MR, L1Cache_Event_Ifetch):
    next_state = L1Cache_State_M; m_curTransitionNextState = next_state;
    h_ifetch_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1InstMiss(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL2Hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    ka_wakeUpAllDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_Ack):
  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_Ack):
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Data):
    next_state = L1Cache_State_ISM; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    u_writeDataToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Data):
    next_state = L1Cache_State_ISM_F; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    uf_writeDataToCacheTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IM, L1Cache_Event_Exclusive_Data):
    next_state = L1Cache_State_MM_W; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    u_writeDataToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    sx_external_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IM_F, L1Cache_Event_Exclusive_Data):
    next_state = L1Cache_State_MM_WF; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    uf_writeDataToCacheTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_IM; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    f_sendAck(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_IM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    f_sendAck(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Data):
  case HASH_FUN(L1Cache_State_SM, L1Cache_Event_Exclusive_Data):
    next_state = L1Cache_State_ISM; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    v_writeDataToCacheVerify(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Data):
  case HASH_FUN(L1Cache_State_SM_F, L1Cache_Event_Exclusive_Data):
    next_state = L1Cache_State_ISM_F; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    vt_writeDataToTBEVerify(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_ISM, L1Cache_Event_All_acks_no_sharers):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_All_acks):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_All_acks_no_sharers):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    sxt_trig_ext_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    gm_sendUnblockM(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_ISM_F, L1Cache_Event_All_acks_no_sharers):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_All_acks):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_All_acks_no_sharers):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_All_acks):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_All_acks_no_sharers):
  case HASH_FUN(L1Cache_State_MM_WF, L1Cache_Event_All_acks_no_sharers):
    next_state = L1Cache_State_MI_F; m_curTransitionNextState = next_state;
    if (!(*m_requestFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    df_issuePUTF(m_tbe_ptr, m_cache_entry_ptr, addr);
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_OM, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_IM; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    e_sendData(m_tbe_ptr, m_cache_entry_ptr, addr);
    pp_incrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_IM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    q_sendDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    pp_incrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    forward_eviction_to_cpu(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Other_GETS_No_Mig):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    et_sendDataSharedFromTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OM_F, L1Cache_Event_Merged_GETS):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    emt_sendDataSharedMultipleFromTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Shared_Ack):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_Shared_Ack):
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    r_setSharerBit(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Data):
    next_state = L1Cache_State_SS; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    u_writeDataToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    hx_external_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uo_updateCurrentOwner(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Exclusive_Data):
    next_state = L1Cache_State_M_W; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    u_writeDataToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    hx_external_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_IS, L1Cache_Event_Shared_Data):
    next_state = L1Cache_State_SS; m_curTransitionNextState = next_state;
    if (!(*m_triggerQueue_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    u_writeDataToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    r_setSharerBit(m_tbe_ptr, m_cache_entry_ptr, addr);
    m_decrementNumberOfMessages(m_tbe_ptr, m_cache_entry_ptr, addr);
    o_checkForCompletion(m_tbe_ptr, m_cache_entry_ptr, addr);
    hx_external_load_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uo_updateCurrentOwner(m_tbe_ptr, m_cache_entry_ptr, addr);
    n_popResponseQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_All_acks):
  case HASH_FUN(L1Cache_State_SS, L1Cache_Event_All_acks_no_sharers):
    next_state = L1Cache_State_S; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    gs_sendUnblockS(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_W, L1Cache_Event_All_acks_no_sharers):
    next_state = L1Cache_State_MM; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    gm_sendUnblockM(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_Store):
    next_state = L1Cache_State_MM_W; m_curTransitionNextState = next_state;
    hh_store_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    uu_profileL1DataHit(m_tbe_ptr, m_cache_entry_ptr, addr);
    k_popMandatoryQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_M_W, L1Cache_Event_All_acks_no_sharers):
    next_state = L1Cache_State_M; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    gm_sendUnblockM(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    j_popTriggerQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Invalidate):
    next_state = L1Cache_State_II; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    q_sendDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Other_GETS_No_Mig):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    sq_sendSharedDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_NC_DMA_GETS):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Other_GETS):
  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Other_GETS_No_Mig):
    next_state = L1Cache_State_OI; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    sq_sendSharedDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Merged_GETS):
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    qm_sendDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Merged_GETS):
    next_state = L1Cache_State_OI; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    qm_sendDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MI, L1Cache_Event_Writeback_Ack):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    t_sendExclusiveDataFromTBEToMemory(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MI_F, L1Cache_Event_Writeback_Ack):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    hh_flush_hit(m_tbe_ptr, m_cache_entry_ptr, addr);
    t_sendExclusiveDataFromTBEToMemory(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_OI, L1Cache_Event_Writeback_Ack):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    qq_sendDataFromTBEToMemory(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Writeback_Ack):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    if (!(*m_unblockFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    g_sendUnblock(m_tbe_ptr, m_cache_entry_ptr, addr);
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_II, L1Cache_Event_Writeback_Nack):
    next_state = L1Cache_State_I; m_curTransitionNextState = next_state;
    s_deallocateTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    kd_wakeUpDependents(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Other_GETX):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Invalidate):
  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Other_GETS):
    next_state = L1Cache_State_IM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    ct_sendExclusiveDataFromTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    pp_incrementNumberOfMessagesByOne(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_NC_DMA_GETS):
    next_state = L1Cache_State_OM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    sq_sendSharedDataFromTBEToCache(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Other_GETS_No_Mig):
    next_state = L1Cache_State_OM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    et_sendDataSharedFromTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

  case HASH_FUN(L1Cache_State_MM_F, L1Cache_Event_Merged_GETS):
    next_state = L1Cache_State_OM_F; m_curTransitionNextState = next_state;
    if (!(*m_responseFromCache_ptr).areNSlotsAvailable(1, clockEdge()))
        return TransitionResult_ResourceStall;
    emt_sendDataSharedMultipleFromTBE(m_tbe_ptr, m_cache_entry_ptr, addr);
    l_popForwardQueue(m_tbe_ptr, m_cache_entry_ptr, addr);
    return TransitionResult_Valid;

      default:
        panic("Invalid transition\n"
              "%s time: %d addr: %#x event: %s state: %s\n",
              name(), curCycle(), addr, event, state);
    }

    return TransitionResult_Valid;
}

} // namespace ruby
} // namespace gem5
